**1. 分布式爬虫主要解决什么问题**

**答：使用分布式主要目的就是为了给爬虫加速。解决了单个 ip 的限制，宽带的影响，以及 CPU 的使用情况和 io 等一系列操作**



**2. scrapy 和 scrapy-redis 有什么区别？为什么选择 redis 数据库？**

**答： scrapy 是一个 Python 爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而 scrapy-redis 一套基于 redis 数据库、运行在 scrapy 框架之上的组件，可以让 scrapy 支持分布式策略，Slaver 端共享 Master 端 redis 数据库里的 item 队列、请求队列和请求指纹集合。**

**为什么选择 redis 数据库，因为 redis 支持主从同步，而且数据都是缓存在内存中的，所以基于 redis 的分布式爬虫，对请求和数据的高频读取效率非常高。**



**3. 爬取速度过快出现了验证码怎么处理**

**答：一般在爬取过程中出现了验证码根据不同的情况，处理不一样。 如果在一开始访问就有验证码,那么就想办法绕开验证码,比如通过 wap 端或者 app 去发现其他接口等，如果不行就得破解验证码了，复杂验证码就需要接入第三方打码平台了。 如果开始的时候没有验证码，爬了一段时间才出现验证码，这个情况就要考虑更换代理 ip 了。 可能因为同一个访问频率高导致的。**



**4. 说一说打开浏览器访问 www.baidu.com 获取到结果，整个流程。**

**答： 浏览器向 DNS 服务器发送 baidu.com 域名解析请求。 DNS 服务器返回解析后的 ip 给客户端浏览器，浏览器想该 ip 发送页面请求。 DNS 服务器接收到请求后，查询该页面，并将页面发送给客户端浏览器。 客户端浏览器接收到页面后，解析页面中的引用，并再次向服务器发送引用资源请求。 服务器接收到资源请求后，查找并返回资源给客户端。 客户端浏览器接收到资源后，渲染，输出页面展现给用户。**



**5. 列出你知道 header 的内容以及信息**

**答： User-Agent：User-Agent 的内容包含发出请求的用户信息。 Accept：指定客户端能够接收的内容类型。 Accept-Encoding：指定浏览器可以支持的 web 服务器返回内容压缩编码类型。 Accept-Language：浏览器可接受的语言。 Connection：表示是否需要持久连接。（HTTP 1.1 默认进行持久连接）。 Content-Length：请求的内容长度。 If-Modified-Since：如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回 304 代码。 Referer：先前网页的地址，当前请求网页紧随其后，即来路。**